{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper this is based attempting to replicate: https://arxiv.org/pdf/2402.01785\n",
    "\n",
    "Useful DoubleML docs: https://docs.doubleml.org/stable/guide/guide.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#package imports\n",
    "import numpy as np\n",
    "import torch\n",
    "import transformers\n",
    "import doubleml\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models \n",
    "#### Baseline Model\n",
    "Uses `LightGBM` package _only_ to estimate nuisance elements on _only_ the tabular data \n",
    "\n",
    "#### Deep Model\n",
    "Implemented exactly as in _Figure 2_ in paper\n",
    "- For text, they use a `RoBERTa` Model pretrained on a `Twitter` Dataset\n",
    "- For images, they use a `VIT` Model pretrained on the `ImageNet-21k` Dataset\n",
    "- For tabular data, they use a `SAINT` model implemented in `pytorch-widedeep`\n",
    "\n",
    "#### Embedding Model \n",
    "Builds on the `Deep Model`, but instead of passing embeddings directly through fusion head/predictive workflow, passes general embedding $H_e$ and data $X_{tab}$ to a boosting algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets (change labelling to be \\textbf)\n",
    "### Tabular\n",
    "`DIAMONDS` dataset, downsampled to create dataset with $N=50,000$ \n",
    "- $\\tilde{X}_{tab}$ is the logarithm of the price\n",
    "- $X_{tab}$ is everything else\n",
    "### Image\n",
    "`CIFAR-10` dataset, specifically the training set ($N=50,000$), which is 32x32 colour images in 10 different classes\n",
    " - $\\tilde{X}_{img}$ is a numerical representation of the label\n",
    " - $X_{img}$ is the image itself\n",
    "### Text\n",
    "`IMDB` dataset, both the training and test samples\n",
    "- $\\tilde{X}_{txt}$ is the binary (positive/negative) sentiment label\n",
    "- $X_{txt}$ is the review itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#process real data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contruct synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up architecture/model: Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deep/embedding common classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up architecture/model: Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up architecture/model: Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML training loop: Deep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ML training loop: Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save and export model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import model (if needed (how to structure selective cell runs?))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting/performance analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
